# Day 07: Echo Bot with Voice Transformation

Welcome to Day 7 of the 30 Days of Voice Agents Challenge\! Today, we've upgraded our Echo Bot. Instead of just replaying your recording, it now transcribes what you said and speaks it back to you in a new voice using a combination of Speech-to-Text and Text-to-Speech APIs.

## ðŸ§  What We Built

  - **Voice Transformation Pipeline**: The application now captures your voice, sends it to the server, and orchestrates a multi-step process:
    1.  **Speech-to-Text**: The recorded audio is first transcribed into text using the **AssemblyAI API**.
    2.  **Text-to-Speech**: The transcribed text is then sent to the **Murf AI API** to generate new audio in a different voice.
    3.  **Audio Playback**: The final audio generated by Murf AI is sent back to the client and played in the browser.
  - **New Server Endpoint**: A new `/tts/echo` endpoint was created in the FastAPI backend to handle this entire workflow. It accepts an audio file, processes it through both APIs, and returns the URL of the final audio clip.
  - **Enhanced UI Feedback**: The user interface now provides more context, displaying the transcribed text with the message "I heard: '[Your words]'" while the new audio plays.

## ðŸ›  Tech Stack

  - **Backend**: `FastAPI`, `uvicorn`, `python-dotenv`, `requests`, `assemblyai`
  - **Frontend**: `HTML`, `Bootstrap`, `JavaScript`, `MediaRecorder` API
  - **Voice APIs**:
      - **Murf AI** for Text-to-Speech
      - **AssemblyAI** for Speech-to-Text

## ðŸš€ Run the App

1.  **Navigate to the project directory:**
    ```bash
    cd day-07/
    ```
2.  **Install the required dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Create a `.env` file** in the `day-07/` directory and add your API keys:
    ```
    MURF_API_KEY="your_murf_api_key_here"
    ASSEMBLYAI_API_KEY="your_assemblyai_api_key_here"
    ```
4.  **Run the FastAPI server:**
    ```bash
    uvicorn main:app --reload
    ```
5.  **Open your browser** and visit http://localhost:8000. Grant microphone permissions if prompted.

## ðŸ“‚ Project Structure

```
day-07/
â”œâ”€â”€ main.py           # Updated with the new /tts/echo endpoint
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html    # UI for the new Echo Bot
â”œâ”€â”€ static/
â”‚   â””â”€â”€ script.js     # Client-side logic for the STT -> TTS pipeline
â”œâ”€â”€ requirements.txt  # Updated with assemblyai
â””â”€â”€ .env              # Now includes ASSEMBLYAI_API_KEY
```

## âœ… Completed Days

  - **Day 01**: Set up a basic FastAPI server with a Bootstrap UI.
  - **Day 02**: Created a `/tts` endpoint to generate speech from text using Murf AI.
  - **Day 03**: Built a client-side interface to interact with the `/tts` endpoint.
  - **Day 04**: Added a client-side echo bot using the `MediaRecorder` API.
  - **Day 05**: Implemented server-side audio upload.
  - **Day 06**: Added Speech-to-Text transcription using AssemblyAI.
  - **Day 07**: Created a voice-transforming echo bot by chaining STT and TTS services.
